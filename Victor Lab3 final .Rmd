---
title: "saidi"
author: "Victor Saidi Phiri"
date: "1/14/2022"
output:
  word_document: default
  html_document: default
---

\`\`

# Load packages

```{r cars}

library(GGally) # for ggcorr	
library(corrr) # network_plot	
library(ggcorrplot) # for ggcorrplot	
library(FactoMineR) # multiple PCA functions	
library(factoextra) # visualisation functions for PCA (e.g. fviz_pca_var)	
library(skimr)
library(paran) # for paran	
library(psych) # for the mixedCor, cortest.bartlett, KMO, fa functions	
library(car) # for vif	
library(GPArotation) # for the psych fa function to have the required rotation functionalities	
library(MVN) # for mvn function	
library(ICS) # for multivariate skew and kurtosis test	
library(tidyverse) # for tidy code
library(sjstats)
library("moments")
library(moments)
library(EFAtools)
library(sjPlot)
 library(QuantPsyc)
```

# Load Dataset

```{r pressure, include=FALSE}
 
Lab3_data <- read.csv("https://raw.githubusercontent.com/kekecsz/SIMM61-Course-materials/main/Exercise_06%20-%20CFA%20and%20EFA/animalrights.csv", sep= ",", header = T)

view(Lab3_data)
 
```

# Data Screening

```{r}
skim(Lab3_data)
```

## Record variables

```{r}
Lab3_data <- Lab3_data %>%mutate(sex =factor(recode(sex,
                                                    "2"="male","1"="female")),
                                 party =factor(recode(party,
                                                   "1"="democrat",
                                                   "2"="republican",
                                                   "3"="other",
                                                   "4"="none")))
table(Lab3_data$sex)
table(complete.cases(Lab3_data))

```

## Drop NAs

```{r}
Lab3_data <- Lab3_data %>% drop_na()#remove missing

Lab3_data %>%describe()

table(Lab3_data$sex)
skim(Lab3_data)

```

This fviz_loadnings_with_cor() is a custom function that will be used in this Lab to visualize some of the results of the exploratory factor analysis.

```{r}
fviz_loadnings_with_cor <- function(mod, axes = 1, loadings_above = 0.4){	
  require(factoextra)	
  require(dplyr)	
  require(ggplot2)	
	
	
	
if(!is.na(as.character(mod$call$call)[1])){	
  if(as.character(mod$call$call)[1] == "PCA"){	
  contrib_and_cov = as.data.frame(rbind(mod[["var"]][["contrib"]], mod[["var"]][["cor"]]))	
	
vars = rownames(mod[["var"]][["contrib"]])	
attribute_type = rep(c("contribution","correlation"), each = length(vars))	
contrib_and_cov = cbind(contrib_and_cov, attribute_type)	
contrib_and_cov	
	
plot_data = cbind(as.data.frame(cbind(contrib_and_cov[contrib_and_cov[,"attribute_type"] == "contribution",axes], contrib_and_cov[contrib_and_cov[,"attribute_type"] == "correlation",axes])), vars)	
names(plot_data) = c("contribution", "correlation", "vars")	
	
plot_data = plot_data %>% 	
  mutate(correlation = round(correlation, 2))	
	
plot = plot_data %>% 	
  ggplot() +	
  aes(x = reorder(vars, contribution), y = contribution, gradient = correlation, label = correlation)+	
  geom_col(aes(fill = correlation)) +	
  geom_hline(yintercept = mean(plot_data$contribution), col = "red", lty = "dashed") + scale_fill_gradient2() +	
  xlab("variable") +	
  coord_flip() +	
  geom_label(color = "black", fontface = "bold", position = position_dodge(0.5))	
	
	
}	
} else if(!is.na(as.character(mod$Call)[1])){	
  	
  if(as.character(mod$Call)[1] == "fa"){	
    loadings_table = mod$loadings %>% 	
      matrix(ncol = ncol(mod$loadings)) %>% 	
      as_tibble() %>% 	
      mutate(variable = mod$loadings %>% rownames()) %>% 	
      gather(factor, loading, -variable) %>% 	
      mutate(sign = if_else(loading >= 0, "positive", "negative"))	
  	
  if(!is.null(loadings_above)){	
    loadings_table[abs(loadings_table[,"loading"]) < loadings_above,"loading"] = NA	
    loadings_table = loadings_table[!is.na(loadings_table[,"loading"]),]	
  }	
  	
  if(!is.null(axes)){	
  	
  loadings_table = loadings_table %>% 	
     filter(factor == paste0("V",axes))	
  }	
  	
  	
  plot = loadings_table %>% 	
      ggplot() +	
      aes(y = loading %>% abs(), x = reorder(variable, abs(loading)), fill = loading, label =       round(loading, 2)) +	
      geom_col(position = "dodge") +	
      scale_fill_gradient2() +	
      coord_flip() +	
      geom_label(color = "black", fill = "white", fontface = "bold", position = position_dodge(0.5)) +	
      facet_wrap(~factor) +	
      labs(y = "Loading strength", x = "Variable")	
  }	
}	
return(plot)	
	
}	

```

# Data exploration

### create are cor matrix

```{r}
df_items = 
  subset(Lab3_data,select=ar1:ar28)

cor = df_items %>% 
  cor() 
```

#Visualization of correlation structure

```{r}

 ggcorr(cor)
 
```

```{r}
ggcorrplot(cor(df_items), p.mat = cor_pmat(df_items),
           hc.order = TRUE, type = "lower")

```

# Network Analysis

```{r}
cor(df_items) %>%
  network_plot(min_cor = 0.6)
```

# Assumptions for Factorability

```{r}
Lab3_Cor <- cor(df_items)%>%round(3)

```

## Kaiser-Meyer-Olkin (KMO) test \#

The KMO test compares the partial correlation matrix\*\* with the regular correlation matrix our overall KMO is larger than 0.6 meaning our data is factorable

```{r}
KMO(Lab3_Cor)

```

## Bartlett Test

p values \> 0.5

not appropriate for our for data, hence we go for KOM results

```{r}
cortest.bartlett(Lab3_Cor,n=149)

```

# Factor extraction

## MultivariateNormality mvnTest:

The Pvalue is less than 0.05- Assumption violated

```{r}
Output <- mvn(Lab3_data[, 1:28], mvnTest = "hz")

Output$multivariateNormality

```

## mvnorm.kur.test

P\<0.05- Assumption Violated

```{r}
mvnorm.kur.test(na.omit(Lab3_data[, 1:28]))
```

## mvnorm.skew.test

P-value less than 0.05- Assumption violated

```{r}
mvnorm.skew.test(na.omit(Lab3_data[,c(1:28)]))
```

Above you can see that both the Henze-Zirkler test and the multivariate skewedness and kurtosis indicate that the assumption of normality is violated. So we will use the paf extraction method \# PAF Analysis 

# Create the first model 5 factors 

```{r}
# Create the first model 5 factors 
EFA_mod1 <- fa(Lab3_Cor, nfactors = 5, fm = "pa")
```

# Sorted communality
highest communality was ar5(90%) with the lowest communality being ar3(20%)
mean communality 441

```{r}

EFA_mod1_common <- as.data.frame(sort(EFA_mod1$communality, decreasing = TRUE))	

EFA_mod1_common

mean(EFA_mod1$communality)# mean communality 

```

## Parallel Test

Choosing ideal number of factors Parallel Test suggest 5 factors

```{r}
fa.parallel(Lab3_Cor, n.obs = nrow(Lab3_data),nfactors = 5, fa = "fa", fm = "pa") 
```

## VSS technique

-   two factors were noticed to be dominant

```{r}
nfactors(Lab3_Cor, n.obs = nrow(Lab3_data)) 
```

## Kaiser Gutman criterion

suggest 3 factors

```{r}
 KGC(Lab3_Cor,eigen_type = "EFA",n_factors = 5)
```

#create a four factor model 

```{r}
EFA_mod2 <- fa(Lab3_Cor, nfactors = 4, fm="pa")	

EFA_mod2
```
## Run Kaiser Gutman criterion
```{r}
KGC(Lab3_Cor,eigen_type = "EFA",n_factors = 4)
```

## Run the parallel Test
```{r}
fa.parallel(Lab3_Cor, n.obs = nrow(Lab3_data),nfactors = 4, fa = "fa", fm = "pa")
```


# Create a two factor model

Two factor model based on analysis of our data

```{r}
EFA_mod3 <- fa(Lab3_Cor, nfactors = 2, fm="pa")	

EFA_mod3	
EFA_mod3_common <- as.data.frame(sort(EFA_mod2$communality, decreasing = TRUE))

EFA_mod3_common
```

\#Mean commonality

```{r}
mean(EFA_mod2$communality)
```

# Rotation

```{r}
fa.diagram(EFA_mod3)# factor analysis diagram without rotation 
```

## PROMAX ROTATION

```{r}
EFA_mod_promax <- fa(Lab3_Cor, nfactors = 2, fm="pa", rotate = "promax")# promax rotation 

fa.diagram(EFA_mod_promax)
```
## Varimax
```{r}
EFA_mod_varimax <- fa(Lab3_Cor, nfactors = 2, fm="pa", rotate = "varimax")# varimax rotation 
fa.diagram(EFA_mod_varimax)
```

#Factor Loadings

```{r}

fviz_loadnings_with_cor(EFA_mod3, axes = 1, loadings_above = 0.4)

```

#Factor loadings

```{r}

fviz_loadnings_with_cor(EFA_mod3, axes = 2, loadings_above = 0.4)	

```

#We redo the process create the subset - by removing valuables with less influence

```{r}

Lab3_items_only2 <- subset(df_items, select = -c(1,8,14,11,25,21))

Lab3_Cor2 <- cor(Lab3_items_only2)


```

#Run the parallel test

```{r}

fa.parallel(Lab3_Cor2, n.obs = nrow(df_items), fa = "fa", fm = "pa")

```

# VSS method

Three measures support 2 factor approach

```{r}

nfactors(Lab3_Cor2, n.obs = nrow(Lab3_items_only2))

```

# create the final model
 

```{r}

EFA_mod4 <- fa(Lab3_Cor2, nfactors = 2, fm = "pa", rotate = "promax")

EFA_mod4

```

## final Model:factors for the final model

```{r}
fa.diagram(EFA_mod4,cut=0.4)# fator analysis structure 

fviz_loadnings_with_cor(EFA_mod4, axes = 1, loadings_above = 0.4)# loadings 

fviz_loadnings_with_cor(EFA_mod4, axes = 2, loadings_above = 0.4)#loadings 
```

### Post extraction communality

```{r}
EFA_mod4_common <- as.data.frame(sort(EFA_mod4$communality, decreasing = TRUE))

EFA_mod4_common
```
#Mean communality 

```{r}
mean(EFA_mod4$communality)

```

```{r}

fa(Lab3_Cor2, nfactors = 2, fm="pa", rotate = "promax")


```

Saving factor output

```{r}

factorscores = factor.scores(Lab3_items_only2[,1:22], EFA_mod4)$scores

ar_factorscores = cbind(Lab3_data, factorscores)

```

Rename factors 

```{r}

art_factorscores<- ar_factorscores %>% 
  rename(exploitation= (PA1),
         Research = (PA2))

```

Regression Model

```{r}
Reg_mod <- lm(liberal ~ exploitation + Research, data = art_factorscores)

summary(Reg_mod)

tab_model(Reg_mod,CSS = list(css.depvarhead = '+color: red;',css.firsttablecol = 'font-weight: bold;',css.summary = 'color: blue;',css.est=TRUE))


```
